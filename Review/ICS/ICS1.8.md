## 第 8 章：虚拟内存 (Virtual Memory) (深度解析版)

虚拟内存 (VM) 是对主存的一个抽象，是现代操作系统必不可少的一部分。它为每个进程提供了一个私有的、一致的地址空间，从而极大地简化了内存管理和程序安全。

### 8.1 核心思想与动机

虚拟内存的核心思想是，为每个进程提供一个独立的、连续的**虚拟地址空间 (Virtual Address Space)**。这个空间的大小由系统的字长决定（例如 64 位系统理论上有 $2^{64}$ 的地址空间）。硬件（MMU）和操作系统内核协同工作，将虚拟地址翻译成真实的**物理地址**。

VM 的三大动机：

1. **作为缓存的工具**：将物理内存 (DRAM) 作为存储在磁盘上的数据的高速缓存。这使得系统可以运行大于物理内存的程序。
2. **作为内存管理的工具**：
    - **简化内存分配**：每个进程都有一个格式统一的虚拟地址空间，内核和用户程序的内存分配（如 `malloc`）变得非常简单，无需关心物理内存的碎片化问题。
    - **简化链接与加载**：链接器可以为所有进程生成地址布局一致的可执行文件，因为每个进程都有自己独立的虚拟地址空间。
3. **作为内存保护的工具**：
    - 通过在页表条目中设置权限位，VM 可以严格控制对内存的访问。一个进程无法访问另一个进程的私有内存，也无法修改内核或只读的代码段，从而实现了强大的内存保护。

### 8.2 地址翻译 (Address Translation)

地址翻译是将一个虚拟地址转换成物理地址的过程。

- **页表 (Page Table)**：是存放在物理内存中的一个核心数据结构，由操作系统为每个进程维护。它本质上是一个数组，其条目称为**页表条目 (Page Table Entry, PTE)**。
- **PTE 的结构**：每个 PTE 将一个**虚拟页 (Virtual Page, VP)** 映射到一个**物理页 (Physical Page, PP)**。它主要包含：
    - 一个**有效位 (Valid Bit)**：指示该虚拟页是否被缓存在物理内存中。
    - 一个**地址字段**：如果有效位为 1，则该字段存储物理页的基地址；否则，它可能指向该页在磁盘上的位置。
    - **权限位**：如 `READ`, `WRITE`, `EXECUTE`, `USER/SUPERVISOR` 等，用于内存保护。

- **缺页 (Page Fault)**：
    当 CPU 访问一个虚拟地址，而 MMU 发现其对应的 PTE 中的有效位为 0 时，就会触发一个**缺页故障**。这是一个同步的、可恢复的异常。

- **缺页处理流程**：
    1. MMU 触发缺页异常，将控制权交给内核的缺页处理程序。
    2. 处理程序选择物理内存中的一个**牺牲页 (victim page)**。如果该页被修改过（dirty），则将其内容写回磁盘。
    3. 处理程序将所需的页面从磁盘加载到牺牲页原来的位置。
    4. 更新页表，将新加载页的 PTE 设置为有效，并指向正确的物理地址。
    5. 处理程序返回，**重新执行**导致缺页的那条指令。此时，由于页面已在内存中，地址翻译可以成功。

    > 这个过程被称为**按需页面调度 (demand paging)**，即只在需要时才将页面调入内存。

### 8.3 加速翻译：TLB (Translation Lookaside Buffer)

由于页表本身存储在内存中，每次地址翻译都可能需要一次额外的内存访问来读取 PTE，这会极大地拖慢速度。

- **TLB**：为了解决这个问题，MMU 内部集成了一个小的、高速的、关于 PTE 的缓存，称为 **TLB**。
- **TLB 命中**：当进行地址翻译时，MMU 首先检查 TLB。如果所需的 PTE 恰好在 TLB 中，MMU 就可以直接获取物理地址，无需访问主存。这非常快。
- **TLB 未命中**：如果 TLB 中没有所需的 PTE，MMU 才需要从主存中的页表获取 PTE，并将其加载到 TLB 中，以备后续使用。
- **局部性**：得益于程序的局部性原理，TLB 的命中率非常高，使得虚拟内存系统在实践中非常高效。

### 8.4 多级页表 (Multi-Level Page Tables)

对于一个 64 位的地址空间，如果使用单级页表，那么页表本身的大小将会是天文数字 ($2^{64-12} \times 8$ Bytes，假设页大小为 4KB)，完全不切实际。

- **解决方案**：使用一个**多级页表的层次结构**。例如，一个四级页表将虚拟地址分为多个部分，第一部分用作一级页表的索引，其条目指向一个二级页表，以此类推。
- **优点**：这种结构极大地节省了空间。如果一级页表的一个条目是空的，那么其对应的整个二级页表就不需要存在。只有当虚拟地址空间中某个区域被使用时，才会为其分配相应的页表。

---

## 第 9 章：存储器层次结构与缓存 (Memory Hierarchy & Caches)

现代计算机系统通过将存储设备组织成一个层次结构，成功地弥合了 CPU 与主存之间巨大的速度差距。

### 9.1 存储技术与 CPU-内存差距

- **存储技术**：从快到慢、从贵到便宜依次为：寄存器、SRAM（用于 CPU 缓存）、DRAM（用于主存）、SSD、旋转磁盘。
- **CPU-内存差距 (The CPU-Memory Gap)**：CPU 的性能增长速度远超 DRAM，导致 CPU 常常需要花费数百个时钟周期来等待内存数据，这形成了性能瓶颈。

### 9.2 局部性原理 (Principle of Locality)

存储器层次结构之所以有效，完全依赖于程序的**局部性原理**。

- **时间局部性 (Temporal Locality)**：如果一个数据项被引用，那么在不久的将来它很可能再次被引用。
- **空间局部性 (Spatial Locality)**：如果一个数据项被引用，那么物理地址上邻近的数据项也很可能在不久的将来被引用。

### 9.3 缓存的核心概念

- **组织结构**：一个缓存的结构可以由元组 `(S, E, B)` 描述：
    - `S = 2^s`: 缓存中的**组 (Set)** 的数量。
    - `E`: **相联度 (Associativity)**，即每组中包含的**行 (Line)** 的数量。
    - `B = 2^b`: **块大小 (Block Size)**，即每个缓存行存储的数据字节数。
    - 缓存总容量为 $C = S \times E \times B$。

- **地址划分**：一个 $m$ 位的地址被划分为三部分，用于在缓存中查找数据：
    - **标记 (Tag)**: $t$ 位，用于唯一标识一个内存块。
    - **组索引 (Set Index)**: $s$ 位，用于决定内存块应该存放在哪个组。
    - **块偏移 (Block Offset)**: $b$ 位，用于在块中定位所需的字节。
    - 关系为 $m = t + s + b$。

- **缓存类型**：
    - **直接映射缓存 (Direct-Mapped)**: $E=1$。每个内存块只能映射到唯一一个缓存组。优点是实现简单，缺点是容易发生**冲突未命中 (Conflict Miss)**。
    - **组相联缓存 (Set Associative)**: $1 < E < C/B$。一个内存块可以映射到特定组中的**任意一行**。这是性能和硬件成本之间的最佳折中方案。
    - **全相联缓存 (Fully Associative)**: $E = C/B$ (只有一个组)。一个内存块可以被放置在缓存的任意一行。命中率最高，但硬件实现非常昂贵和复杂。

### 9.4 编写缓存友好的代码

编写能够高效利用缓存的代码是性能优化的关键。

- **核心思想**：最大化程序的**时间局部性**和**空间局部性**。
- **主要策略**：
    1. **聚焦内层循环**：程序的大部分时间都消耗在内层循环中。
    2. **最大化空间局部性**：在内层循环中，尽量以**步长为 1** 的模式来访问数据。例如，在 C 语言中，按行遍历二维数组比按列遍历要快得多。
    3. **最大化时间局部性**：对于一个数据，一旦它被加载到缓存，就应该尽可能多地使用它。
- **分块 (Blocking)**：是一种重要的缓存优化技术。它将数据划分为大小与缓存相匹配的**块**，并通过围绕这些块进行计算，来最大化对加载到缓存中的数据块的重复利用，从而显著提高时间局部性。

---
