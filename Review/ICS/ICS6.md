# ICS

## 第 8 章：虚拟内存 (Virtual Memory)

虚拟内存是计算机系统最重要的概念之一。它为每个进程提供了一个大的、一致的和私有的地址空间，从而极大地简化了内存管理和程序编写。

### 8.1 什么是虚拟内存？

虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件之间精密交互的产物。它为每个进程提供了一个假象，让进程感觉自己拥有一个私有的、从 0 开始的连续地址空间，称为**虚拟地址空间 (virtual address space)**。

实际上，这些虚拟地址会由硬件（**MMU, 内存管理单元**）和操作系统协作，翻译成**物理地址**，数据实际存储在物理主存（DRAM）中。

### 8.2 虚拟内存作为缓存的工具

虚拟内存系统将虚拟地址空间分割成大小固定的块，称为**虚拟页 (Virtual Pages, VP)**。同样，物理内存也被分割成相同大小的**物理页 (Physical Pages, PP)**。物理内存（DRAM）在这里扮演了磁盘上数据的高速缓存角色。

- **页表 (Page Table)**：操作系统为每个进程维护一个页表，它是一个将虚拟页映射到物理页的数据结构。
- **页命中 (Page Hit)**：当 CPU 需要访问一个虚拟地址时，如果其对应的物理页恰好在主存中，MMU 能直接完成地址翻译，这就是一次页命中。
- **缺页 (Page Fault)**：如果对应的物理页不在主存中（即 DRAM 缓存未命中），就会触发一个**缺页异常**。
- **缺页处理**：
    1. 缺页异常会陷入内核。
    2. 内核中的缺页处理程序会从磁盘加载所需的页面到主存的一个物理页中。如果主存已满，会选择一个“牺牲”页将其换出。
    3. 更新页表，以反映新的映射关系。
    4. 处理程序返回，并**重新执行**导致缺页的指令。此时，由于数据已在内存中，指令可以成功执行。
    - 这种在需要时才将页面从磁盘加载到内存的策略称为**按需页面调度 (demand paging)**。

### 8.3 虚拟内存作为内存管理的工具

- **简化内存分配**：虚拟内存为每个进程提供了一个统一的线性地址空间，使得内核和用户程序在分配内存时无需关心物理内存的碎片化问题。
- **简化链接与加载**：每个进程的地址空间布局都是一致的（例如，代码段总是从相同的虚拟地址开始），这极大地简化了链接器和加载器的设计。
- **共享代码和数据**：操作系统可以将不同进程的虚拟页映射到相同的物理页，从而实现代码和数据（如 C 标准库）的共享，节省了宝贵的内存资源。

### 8.4 虚拟内存作为内存保护的工具

虚拟内存通过在页表条目（PTE）中添加权限位（如读、写、执行、用户/内核模式），提供了一种精确的内存保护机制。

- MMU 在每次地址翻译时都会检查这些权限位。
- 如果一条指令试图违反权限（例如，用户模式下的程序试图写入一个只读的代码段），CPU 会触发一个**通用保护故障 (general protection fault)**，内核会捕获这个故障并通常会终止该进程。

### 8.5 地址翻译与 TLB

由于页表存储在主存中，每次地址翻译都可能需要额外的内存访问，这会降低效率。为了加速地址翻译，MMU 中包含了一个小的、关于页表条目的高速缓存，称为**翻译后备缓冲区 (Translation Lookaside Buffer, TLB)**。

- 当 MMU 进行地址翻译时，它首先检查 TLB。
- **TLB 命中**：如果所需的 PTE 在 TLB 中，MMU 可以直接获取物理地址，无需访问主存。这非常快。
- **TLB 未命中**：如果 PTE 不在 TLB 中，MMU 才需要从主存中的页表获取 PTE，并将其加载到 TLB 中，以备后续使用。

---

## 第 9 章：存储器层次结构

现代计算机系统的存储器被组织成一个层次结构，它利用了程序访问的**局部性原理**，为我们提供了既大又快的存储系统。

### 9.1 存储技术与趋势

- **SRAM**：速度快，价格昂贵，用于构建 CPU 缓存。
- **DRAM**：速度比 SRAM 慢，但更便宜，用于构建主存。
- **磁盘**：速度最慢，但容量巨大且非易失，用于长期存储。
- **CPU-内存差距**：CPU 的速度增长远快于 DRAM，导致了所谓的“**存储墙 (Memory Wall)**”。CPU 常常需要花费数百个时钟周期等待数据从主存到达。

### 9.2 局部性原理 (Principle of Locality)

程序倾向于引用邻近于其他最近引用过的数据项的数据项，或者最近引用过的数据项本身。这是存储器层次结构能够工作的根本原因。

- **时间局部性 (Temporal Locality)**：如果一个数据项被引用，那么在不久的将来它很可能再次被引用。
- **空间局部性 (Spatial Locality)**：如果一个数据项被引用，那么在不久的将来它附近的数据项也很可能被引用。

### 9.3 缓存基础 (Cache)

- **缓存**：一个更小、更快的存储设备，用作更大、更慢设备中数据子集的暂存区。
- **缓存命中 (Cache Hit)**：当程序需要的数据恰好在缓存中时。
- **缓存未命中 (Cache Miss)**：当数据不在缓存中时，需要从下一级存储中获取，这会带来显著的**未命中惩罚 (miss penalty)**。
- **缓存的组织 (S, E, B)**：
    - `B`：块大小 (Block size)。
    - `S`：组数 (Number of sets)。
    - `E`：相联度 (Associativity)，即每组中的行数。
- **缓存类型**：
    - **直接映射 (`E=1`)**：每个内存块只能映射到缓存中的一个特定行。简单但易发生冲突未命中。
    - **组相联 (`1 < E < C/B`)**：一个内存块可以映射到特定组中的任意一行。是性能和成本的良好折中。
    - **全相联 (`E = C/B`)**：一个内存块可以映射到缓存中的任意一行。最灵活但硬件实现最复杂。

### 9.4 编写缓存友好的代码

编写能够有效利用缓存的代码是性能优化的关键。

- **核心思想**：最大化程序的空间和时间局部性。
- **基本准则**：
    1. **聚焦内层循环**：大部分计算都发生在循环中。
    2. **最大化空间局部性**：在内层循环中，尽量以**步长为 1** 的模式访问数据。
    3. **最大化时间局部性**：让被重复引用的数据项尽可能地在缓存中停留。

- **示例：矩阵乘法**
    - 一个简单的 `ijk` 循环顺序会导致对第二个矩阵的访问是按列的，步长很大，空间局部性极差。
    - 通过交换循环顺序（如改为 `kij` 或 `jik`），可以改变内存访问模式，将一个或多个数组的访问变为步长为 1，从而显著减少缓存未命中次数，将性能提升数倍。

- **分块 (Blocking)**：一种高级的优化技术，通过将数据分成小的“块”，并让计算围绕这些块进行，从而将一个数据集加载到缓存中并最大化地重复使用它，极大地提高了时间局部性。

---
